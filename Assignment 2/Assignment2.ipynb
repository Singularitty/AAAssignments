{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fcab862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Models and selection methods\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Binary classifier metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix, accuracy_score\n",
    "# Linear regression metrics\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, max_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "#Pré-Processamento de dados\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PowerTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d0df717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatisticas para classificadores\n",
    "def printClassResults(truth, preds):\n",
    "    print(\"The Accuracy is: %7.4f\" % accuracy_score(truth, preds))\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(truth, preds))\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(truth, preds))\n",
    "    print(\"The F1 score is: %7.4f\" % f1_score(truth, preds))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(truth, preds))\n",
    "    print()\n",
    "    print(\"This is the Confusion Matrix\")\n",
    "    print(pd.DataFrame(confusion_matrix(truth, preds)))\n",
    "\n",
    "# Plot das previsoes vs dados reais\n",
    "def displayPlot(preds, truth):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.scatter(preds, truth)\n",
    "    plt.axline((0, 0), slope=1, color=\"red\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491c9542",
   "metadata": {},
   "source": [
    "## Pré-Processamento dos dados\n",
    "Preparação do dataset - importação, normalização e preenchimento dos missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "650c2619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.919      2.6909     0.         ... 7.253      0.         0.        ]\n",
      " [4.17       2.1144     0.         ... 7.257      0.         0.        ]\n",
      " [3.932      3.2512     0.         ... 7.601      0.         0.        ]\n",
      " ...\n",
      " [4.29477099 3.47122594 0.         ... 7.69932352 0.         0.        ]\n",
      " [4.56037572 3.89639031 0.         ... 7.90880199 0.         0.        ]\n",
      " [4.04509735 2.84718513 0.         ... 6.86331402 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Criar dataframe\n",
    "bio_a = pd.read_csv('biodegradable_a.csv')\n",
    "#Separação das 41 variáveis do y\n",
    "X_bio_a=bio_a.drop(columns=[\"Biodegradable\"])\n",
    "y_bio_a=bio_a['Biodegradable']\n",
    "#Converter para numpy array\n",
    "Xc_bio= X_bio_a.to_numpy()\n",
    "yc_bio= y_bio_a.to_numpy()\n",
    "print(Xc_bio)\n",
    "# Divisão do dataset em training set e independent validation set\n",
    "X_bio_train, X_bio_test, y_bio_train, y_bio_test = train_test_split(Xc_bio, yc_bio, test_size=0.25, random_state=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657f391e",
   "metadata": {},
   "source": [
    "Passamos agora à normalização dos dados. Vão ser escolhidos os seguintes métodos de normalização para comparar mais tarde: MinMax Scaler, Standard Scaler e Power Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d380d929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6   \\\n",
      "0    -1.857579  0.168452 -0.298474 -0.092755 -0.329914 -0.193061 -0.766057   \n",
      "1    -1.854459 -1.019003 -0.298474 -0.092755 -0.329914 -0.193061 -0.766057   \n",
      "2     0.430395  1.193057 -0.298474 -0.092755 -0.329914 -0.193061 -0.766057   \n",
      "3     0.421222 -0.036376 -0.298474 -0.092755 -0.329914 -0.193061  1.293260   \n",
      "4    -0.751657 -1.775834 -0.298474 -0.092755 -0.329914 -0.193061 -0.766057   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "3418  1.664765  0.591478  3.349907 -0.092755 -0.329914 -0.193061  1.293260   \n",
      "3419  0.244807 -0.641362 -0.298474 -0.092755 -0.329914 -0.193061 -0.766057   \n",
      "3420 -0.562774  0.804821 -0.298474 -0.092755 -0.329914 -0.193061 -0.766057   \n",
      "3421  0.755840 -0.060657 -0.298474 -0.092755 -0.329914 -0.193061  1.293260   \n",
      "3422  1.054821 -0.193085 -0.298474       NaN -0.329914 -0.193061  1.293260   \n",
      "\n",
      "            7         8         9   ...        31        32        33  \\\n",
      "0    -0.176119 -1.219043  1.235903  ... -0.113263 -0.457263 -0.427509   \n",
      "1          NaN  0.819561 -0.615911  ... -0.113263 -0.457263 -0.427509   \n",
      "2     0.291224 -1.219043  0.109793  ... -0.113263 -0.457263 -0.427509   \n",
      "3     1.092849 -1.219043  0.109793  ... -0.113263 -0.457263 -0.427509   \n",
      "4    -0.466588  0.084134 -1.585803  ... -0.113263 -0.457263 -0.427509   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "3418       NaN -1.219043  0.711807  ... -0.113263 -0.457263 -0.427509   \n",
      "3419 -0.292831  0.819561  0.109793  ... -0.113263 -0.457263 -0.427509   \n",
      "3420       NaN  0.084134  0.109793  ... -0.113263 -0.457263 -0.427509   \n",
      "3421  0.813510  1.329679 -1.585803  ... -0.113263 -0.457263 -0.427509   \n",
      "3422  0.414988  0.819561  1.235903  ... -0.113263 -0.457263 -0.427509   \n",
      "\n",
      "            34        35        36        37        38        39        40  \n",
      "0     1.321538 -0.636159  2.246219 -0.468445 -0.949614 -0.222886 -0.233042  \n",
      "1     1.553357 -2.135502  0.987608  2.123623 -2.097699 -0.222886       NaN  \n",
      "2    -0.874182  0.281114  0.540742 -0.468445  0.064084 -0.222886 -0.233042  \n",
      "3    -0.874182  0.456898  0.227531 -0.468445  0.252883 -0.222886 -0.233042  \n",
      "4     0.821645       NaN -1.140070 -0.468445 -1.096429 -0.222886       NaN  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "3418  1.321538  2.082672       NaN -0.468445  1.506523 -0.222886 -0.233042  \n",
      "3419  1.553357 -0.191679 -0.552582 -0.468445  0.648379 -0.222886 -0.233042  \n",
      "3420  1.321538  0.404293  2.169303 -0.468445 -0.276885 -0.222886 -0.233042  \n",
      "3421 -0.874182  0.397339 -1.456878 -0.468445  0.039927 -0.222886 -0.233042  \n",
      "3422 -0.874182       NaN -0.167892 -0.468445  0.764431  4.486606 -0.233042  \n",
      "\n",
      "[3423 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "#Passemos à normalização dos dados\n",
    "##NOTA: A partir daqui é só experiência (só para se poder continuar código)\n",
    "scaler_p = PowerTransformer()\n",
    "scaler_st = StandardScaler()\n",
    "scaler_min= MinMaxScaler()\n",
    "\n",
    "#Transformar dados\n",
    "X_bio_train_p=scaler_p.fit_transform(X_bio_train)\n",
    "X_bio_test_p=scaler_p.fit_transform(X_bio_test)\n",
    "\n",
    "X_bio_train_st=scaler_st.fit_transform(X_bio_train)\n",
    "X_bio_test_st=scaler_st.fit_transform(X_bio_test)\n",
    "\n",
    "X_bio_train_min=scaler_min.fit_transform(X_bio_train)\n",
    "X_bio_test_min=scaler_min.fit_transform(X_bio_test)\n",
    "\n",
    "print(pd.DataFrame(X_bio_train_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90d5585",
   "metadata": {},
   "source": [
    "Com os dados normalizados, podemos passar à imputação dos valores em falta. Escolheu-se o método de imputação utilizando o K-Nearest Neighbours em todos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23553b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6   \\\n",
      "0    -1.857579  0.168452 -0.298474 -0.092755 -0.329914 -0.193061 -0.766057   \n",
      "1    -1.854459 -1.019003 -0.298474 -0.092755 -0.329914 -0.193061 -0.766057   \n",
      "2     0.430395  1.193057 -0.298474 -0.092755 -0.329914 -0.193061 -0.766057   \n",
      "3     0.421222 -0.036376 -0.298474 -0.092755 -0.329914 -0.193061  1.293260   \n",
      "4    -0.751657 -1.775834 -0.298474 -0.092755 -0.329914 -0.193061 -0.766057   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "3418  1.664765  0.591478  3.349907 -0.092755 -0.329914 -0.193061  1.293260   \n",
      "3419  0.244807 -0.641362 -0.298474 -0.092755 -0.329914 -0.193061 -0.766057   \n",
      "3420 -0.562774  0.804821 -0.298474 -0.092755 -0.329914 -0.193061 -0.766057   \n",
      "3421  0.755840 -0.060657 -0.298474 -0.092755 -0.329914 -0.193061  1.293260   \n",
      "3422  1.054821 -0.193085 -0.298474 -0.092755 -0.329914 -0.193061  1.293260   \n",
      "\n",
      "            7         8         9   ...        31        32        33  \\\n",
      "0    -0.176119 -1.219043  1.235903  ... -0.113263 -0.457263 -0.427509   \n",
      "1    -1.956446  0.819561 -0.615911  ... -0.113263 -0.457263 -0.427509   \n",
      "2     0.291224 -1.219043  0.109793  ... -0.113263 -0.457263 -0.427509   \n",
      "3     1.092849 -1.219043  0.109793  ... -0.113263 -0.457263 -0.427509   \n",
      "4    -0.466588  0.084134 -1.585803  ... -0.113263 -0.457263 -0.427509   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "3418  0.261982 -1.219043  0.711807  ... -0.113263 -0.457263 -0.427509   \n",
      "3419 -0.292831  0.819561  0.109793  ... -0.113263 -0.457263 -0.427509   \n",
      "3420 -1.354518  0.084134  0.109793  ... -0.113263 -0.457263 -0.427509   \n",
      "3421  0.813510  1.329679 -1.585803  ... -0.113263 -0.457263 -0.427509   \n",
      "3422  0.414988  0.819561  1.235903  ... -0.113263 -0.457263 -0.427509   \n",
      "\n",
      "            34        35        36        37        38        39        40  \n",
      "0     1.321538 -0.636159  2.246219 -0.468445 -0.949614 -0.222886 -0.233042  \n",
      "1     1.553357 -2.135502  0.987608  2.123623 -2.097699 -0.222886 -0.233042  \n",
      "2    -0.874182  0.281114  0.540742 -0.468445  0.064084 -0.222886 -0.233042  \n",
      "3    -0.874182  0.456898  0.227531 -0.468445  0.252883 -0.222886 -0.233042  \n",
      "4     0.821645 -0.857359 -1.140070 -0.468445 -1.096429 -0.222886 -0.233042  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "3418  1.321538  2.082672  0.886762 -0.468445  1.506523 -0.222886 -0.233042  \n",
      "3419  1.553357 -0.191679 -0.552582 -0.468445  0.648379 -0.222886 -0.233042  \n",
      "3420  1.321538  0.404293  2.169303 -0.468445 -0.276885 -0.222886 -0.233042  \n",
      "3421 -0.874182  0.397339 -1.456878 -0.468445  0.039927 -0.222886 -0.233042  \n",
      "3422 -0.874182  0.664526 -0.167892 -0.468445  0.764431  4.486606 -0.233042  \n",
      "\n",
      "[3423 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "#Tratamento dos Missing values -> Utilizar Imputação de KNN\n",
    "imputer = KNNImputer(n_neighbors=3, weights=\"uniform\")\n",
    "\n",
    "X_bio_train_p=imputer.fit_transform(X_bio_train_p)\n",
    "X_bio_test_p=imputer.fit_transform(X_bio_test_p)\n",
    "\n",
    "X_bio_train_st=imputer.fit_transform(X_bio_train_st)\n",
    "X_bio_test_st=imputer.fit_transform(X_bio_test_st)\n",
    "\n",
    "X_bio_train_min=imputer.fit_transform(X_bio_train_min)\n",
    "X_bio_test_min=imputer.fit_transform(X_bio_test_min)\n",
    "\n",
    "print(pd.DataFrame(X_bio_train_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3de335",
   "metadata": {},
   "source": [
    "Resta apenas ver quais são as variáveis mais relevantes. Para tal, vamos utilizar o SelectFromModel do scikit-learn utilizando RandomForests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "689a3a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr=RandomForestClassifier(random_state=45)\n",
    "sel = SelectFromModel(estimator=rfr, threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381a2adb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
