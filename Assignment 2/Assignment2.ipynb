{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fcab862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Models and selection methods\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Binary classifier metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix, accuracy_score\n",
    "# Linear regression metrics\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error, max_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "#Pré-Processamento de dados\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PowerTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import SelectFromModel, SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d0df717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatisticas para classificadores\n",
    "def printClassResults(truth, preds):\n",
    "    print(\"The Accuracy is: %7.4f\" % accuracy_score(truth, preds))\n",
    "    print(\"The Precision is: %7.4f\" % precision_score(truth, preds))\n",
    "    print(\"The Recall is: %7.4f\" % recall_score(truth, preds))\n",
    "    print(\"The F1 score is: %7.4f\" % f1_score(truth, preds))\n",
    "    print(\"The Matthews correlation coefficient is: %7.4f\" % matthews_corrcoef(truth, preds))\n",
    "    print()\n",
    "    print(\"This is the Confusion Matrix\")\n",
    "    print(pd.DataFrame(confusion_matrix(truth, preds)))\n",
    "\n",
    "# Previsao de resultados com cross validation\n",
    "def CrossValidation(X_TRAIN, y_TRAIN, kf, model):\n",
    "    TRUTH=None\n",
    "    PREDS=None\n",
    "    for train_index, test_index in kf.split(X_TRAIN):\n",
    "        X_train, X_test = X_TRAIN[train_index], X_TRAIN[test_index]\n",
    "        y_train, y_test = y_TRAIN[train_index], y_TRAIN[test_index]\n",
    "        temp_model = clone(model)\n",
    "        temp_model.fit(X_train, y_train)\n",
    "        preds = temp_model.predict(X_test)\n",
    "        if TRUTH is None:\n",
    "            PREDS=preds\n",
    "            TRUTH=y_test\n",
    "        else:\n",
    "            PREDS=np.hstack((PREDS, preds))\n",
    "            TRUTH=np.hstack((TRUTH, y_test))\n",
    "    return (TRUTH, PREDS)\n",
    "    \n",
    "# Model testing rapido\n",
    "def naif_model_testing(X_train, X_test, y_train, y_test):\n",
    "    rfr= RandomForestClassifier(n_jobs=-1)\n",
    "    rfr.fit(X_train, y_train)\n",
    "    dtr= DecisionTreeClassifier(max_depth=5)\n",
    "    dtr.fit(X_train, y_train)\n",
    "    lmr=LogisticRegression(n_jobs=-1)\n",
    "    lmr.fit(X_train, y_train)\n",
    "    rf_preds=rfr.predict(X_test)\n",
    "    dt_preds=dtr.predict(X_test)\n",
    "    lr_preds=lmr.predict(X_test)\n",
    "    scores = [f1_score(y_test, rf_preds),f1_score(y_test, dt_preds),f1_score(y_test, lr_preds)]\n",
    "    print(\"F1 RFs: %7.4f\" % f1_score(y_test, rf_preds))\n",
    "    print(\"F1 DTs: %7.4f\" % f1_score(y_test, dt_preds))\n",
    "    print(\"F1 LRs: %7.4f\" % f1_score(y_test, lr_preds))\n",
    "    print(\"F1 Avg:  %7.4f\" % (sum(scores) / len(scores)))\n",
    "    return (sum(scores) / len(scores))\n",
    "\n",
    "def Step_for(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    N,M=X_train.shape\n",
    "\n",
    "    #Vamos usar random forests\n",
    "    rfr=RandomForestClassifier(random_state=45)\n",
    "    sfs = SequentialFeatureSelector(rfr, n_features_to_select=10)\n",
    "    sfs.fit(X_train, y_train)\n",
    "\n",
    "    #get the relevant columns\n",
    "    features=sfs.get_support()\n",
    "    Features_selected =np.arange(M)[features]\n",
    "    print(\"The features selected are columns: \", Features_selected)\n",
    "\n",
    "    nX_train=sfs.transform(X_train)\n",
    "    nX_test=sfs.transform(X_test)\n",
    "\n",
    "    f1_avg = naif_model_testing(nX_train, nX_test, y_train, y_test)\n",
    "    return (f1_avg, nX_train, nX_test)\n",
    "    \n",
    "def ML_Sel(X_train, X_test, y_train, y_test, thresh):\n",
    "    N,M=X_train.shape\n",
    "\n",
    "    rfr=RandomForestClassifier(random_state=45, n_jobs=-1)\n",
    "    sel = SelectFromModel(estimator=rfr, threshold=thresh)\n",
    "    sel.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Default threshold: \", sel.threshold_)\n",
    "    features=sel.get_support()\n",
    "    Features_selected =np.arange(M)[features]\n",
    "    print(\"The features selected are columns: \", Features_selected)\n",
    "    nX_train=sel.transform(X_train)\n",
    "    nX_test=sel.transform(X_test)\n",
    "    f1_avg = naif_model_testing(nX_train, nX_test, y_train, y_test)\n",
    "    return (f1_avg, nX_train, nX_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491c9542",
   "metadata": {},
   "source": [
    "## Pré-Processamento dos dados\n",
    "Preparação do dataset - importação, normalização e preenchimento dos missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "650c2619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Criar dataframe\n",
    "bio_a = pd.read_csv('biodegradable_a.csv')\n",
    "#Separação das 41 variáveis do y\n",
    "X_bio_a=bio_a.drop(columns=[\"Biodegradable\"])\n",
    "y_bio_a=bio_a['Biodegradable'].apply(lambda x : 1 if x == 'RB' else 0)\n",
    "#Converter para numpy array\n",
    "Xc_bio= X_bio_a.to_numpy()\n",
    "yc_bio= y_bio_a.to_numpy()\n",
    "# Divisão do dataset em training set e independent validation set\n",
    "X_bio_train, X_bio_test, y_bio_train, y_bio_test = train_test_split(Xc_bio, yc_bio, test_size=0.25, random_state=512)\n",
    "# Kfold\n",
    "kf = KFold(n_splits=16, shuffle=True, random_state = 274)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657f391e",
   "metadata": {},
   "source": [
    "Passamos agora à normalização dos dados. Vão ser escolhidos os seguintes métodos de normalização para comparar mais tarde: MinMax Scaler, Standard Scaler e Power Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d380d929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.857579</td>\n",
       "      <td>0.168452</td>\n",
       "      <td>-0.298474</td>\n",
       "      <td>-0.092755</td>\n",
       "      <td>-0.329914</td>\n",
       "      <td>-0.193061</td>\n",
       "      <td>-0.766057</td>\n",
       "      <td>-0.176119</td>\n",
       "      <td>-1.219043</td>\n",
       "      <td>1.235903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113263</td>\n",
       "      <td>-0.457263</td>\n",
       "      <td>-0.427509</td>\n",
       "      <td>1.321538</td>\n",
       "      <td>-0.636159</td>\n",
       "      <td>2.246219</td>\n",
       "      <td>-0.468445</td>\n",
       "      <td>-0.949614</td>\n",
       "      <td>-0.222886</td>\n",
       "      <td>-0.233042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.854459</td>\n",
       "      <td>-1.019003</td>\n",
       "      <td>-0.298474</td>\n",
       "      <td>-0.092755</td>\n",
       "      <td>-0.329914</td>\n",
       "      <td>-0.193061</td>\n",
       "      <td>-0.766057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.819561</td>\n",
       "      <td>-0.615911</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113263</td>\n",
       "      <td>-0.457263</td>\n",
       "      <td>-0.427509</td>\n",
       "      <td>1.553357</td>\n",
       "      <td>-2.135502</td>\n",
       "      <td>0.987608</td>\n",
       "      <td>2.123623</td>\n",
       "      <td>-2.097699</td>\n",
       "      <td>-0.222886</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.430395</td>\n",
       "      <td>1.193057</td>\n",
       "      <td>-0.298474</td>\n",
       "      <td>-0.092755</td>\n",
       "      <td>-0.329914</td>\n",
       "      <td>-0.193061</td>\n",
       "      <td>-0.766057</td>\n",
       "      <td>0.291224</td>\n",
       "      <td>-1.219043</td>\n",
       "      <td>0.109793</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113263</td>\n",
       "      <td>-0.457263</td>\n",
       "      <td>-0.427509</td>\n",
       "      <td>-0.874182</td>\n",
       "      <td>0.281114</td>\n",
       "      <td>0.540742</td>\n",
       "      <td>-0.468445</td>\n",
       "      <td>0.064084</td>\n",
       "      <td>-0.222886</td>\n",
       "      <td>-0.233042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.421222</td>\n",
       "      <td>-0.036376</td>\n",
       "      <td>-0.298474</td>\n",
       "      <td>-0.092755</td>\n",
       "      <td>-0.329914</td>\n",
       "      <td>-0.193061</td>\n",
       "      <td>1.293260</td>\n",
       "      <td>1.092849</td>\n",
       "      <td>-1.219043</td>\n",
       "      <td>0.109793</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113263</td>\n",
       "      <td>-0.457263</td>\n",
       "      <td>-0.427509</td>\n",
       "      <td>-0.874182</td>\n",
       "      <td>0.456898</td>\n",
       "      <td>0.227531</td>\n",
       "      <td>-0.468445</td>\n",
       "      <td>0.252883</td>\n",
       "      <td>-0.222886</td>\n",
       "      <td>-0.233042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.751657</td>\n",
       "      <td>-1.775834</td>\n",
       "      <td>-0.298474</td>\n",
       "      <td>-0.092755</td>\n",
       "      <td>-0.329914</td>\n",
       "      <td>-0.193061</td>\n",
       "      <td>-0.766057</td>\n",
       "      <td>-0.466588</td>\n",
       "      <td>0.084134</td>\n",
       "      <td>-1.585803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113263</td>\n",
       "      <td>-0.457263</td>\n",
       "      <td>-0.427509</td>\n",
       "      <td>0.821645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.140070</td>\n",
       "      <td>-0.468445</td>\n",
       "      <td>-1.096429</td>\n",
       "      <td>-0.222886</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>1.664765</td>\n",
       "      <td>0.591478</td>\n",
       "      <td>3.349907</td>\n",
       "      <td>-0.092755</td>\n",
       "      <td>-0.329914</td>\n",
       "      <td>-0.193061</td>\n",
       "      <td>1.293260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.219043</td>\n",
       "      <td>0.711807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113263</td>\n",
       "      <td>-0.457263</td>\n",
       "      <td>-0.427509</td>\n",
       "      <td>1.321538</td>\n",
       "      <td>2.082672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.468445</td>\n",
       "      <td>1.506523</td>\n",
       "      <td>-0.222886</td>\n",
       "      <td>-0.233042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>0.244807</td>\n",
       "      <td>-0.641362</td>\n",
       "      <td>-0.298474</td>\n",
       "      <td>-0.092755</td>\n",
       "      <td>-0.329914</td>\n",
       "      <td>-0.193061</td>\n",
       "      <td>-0.766057</td>\n",
       "      <td>-0.292831</td>\n",
       "      <td>0.819561</td>\n",
       "      <td>0.109793</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113263</td>\n",
       "      <td>-0.457263</td>\n",
       "      <td>-0.427509</td>\n",
       "      <td>1.553357</td>\n",
       "      <td>-0.191679</td>\n",
       "      <td>-0.552582</td>\n",
       "      <td>-0.468445</td>\n",
       "      <td>0.648379</td>\n",
       "      <td>-0.222886</td>\n",
       "      <td>-0.233042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>-0.562774</td>\n",
       "      <td>0.804821</td>\n",
       "      <td>-0.298474</td>\n",
       "      <td>-0.092755</td>\n",
       "      <td>-0.329914</td>\n",
       "      <td>-0.193061</td>\n",
       "      <td>-0.766057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084134</td>\n",
       "      <td>0.109793</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113263</td>\n",
       "      <td>-0.457263</td>\n",
       "      <td>-0.427509</td>\n",
       "      <td>1.321538</td>\n",
       "      <td>0.404293</td>\n",
       "      <td>2.169303</td>\n",
       "      <td>-0.468445</td>\n",
       "      <td>-0.276885</td>\n",
       "      <td>-0.222886</td>\n",
       "      <td>-0.233042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>0.755840</td>\n",
       "      <td>-0.060657</td>\n",
       "      <td>-0.298474</td>\n",
       "      <td>-0.092755</td>\n",
       "      <td>-0.329914</td>\n",
       "      <td>-0.193061</td>\n",
       "      <td>1.293260</td>\n",
       "      <td>0.813510</td>\n",
       "      <td>1.329679</td>\n",
       "      <td>-1.585803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113263</td>\n",
       "      <td>-0.457263</td>\n",
       "      <td>-0.427509</td>\n",
       "      <td>-0.874182</td>\n",
       "      <td>0.397339</td>\n",
       "      <td>-1.456878</td>\n",
       "      <td>-0.468445</td>\n",
       "      <td>0.039927</td>\n",
       "      <td>-0.222886</td>\n",
       "      <td>-0.233042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>1.054821</td>\n",
       "      <td>-0.193085</td>\n",
       "      <td>-0.298474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.329914</td>\n",
       "      <td>-0.193061</td>\n",
       "      <td>1.293260</td>\n",
       "      <td>0.414988</td>\n",
       "      <td>0.819561</td>\n",
       "      <td>1.235903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113263</td>\n",
       "      <td>-0.457263</td>\n",
       "      <td>-0.427509</td>\n",
       "      <td>-0.874182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.167892</td>\n",
       "      <td>-0.468445</td>\n",
       "      <td>0.764431</td>\n",
       "      <td>4.486606</td>\n",
       "      <td>-0.233042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3423 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -1.857579  0.168452 -0.298474 -0.092755 -0.329914 -0.193061 -0.766057   \n",
       "1    -1.854459 -1.019003 -0.298474 -0.092755 -0.329914 -0.193061 -0.766057   \n",
       "2     0.430395  1.193057 -0.298474 -0.092755 -0.329914 -0.193061 -0.766057   \n",
       "3     0.421222 -0.036376 -0.298474 -0.092755 -0.329914 -0.193061  1.293260   \n",
       "4    -0.751657 -1.775834 -0.298474 -0.092755 -0.329914 -0.193061 -0.766057   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3418  1.664765  0.591478  3.349907 -0.092755 -0.329914 -0.193061  1.293260   \n",
       "3419  0.244807 -0.641362 -0.298474 -0.092755 -0.329914 -0.193061 -0.766057   \n",
       "3420 -0.562774  0.804821 -0.298474 -0.092755 -0.329914 -0.193061 -0.766057   \n",
       "3421  0.755840 -0.060657 -0.298474 -0.092755 -0.329914 -0.193061  1.293260   \n",
       "3422  1.054821 -0.193085 -0.298474       NaN -0.329914 -0.193061  1.293260   \n",
       "\n",
       "            7         8         9   ...        31        32        33  \\\n",
       "0    -0.176119 -1.219043  1.235903  ... -0.113263 -0.457263 -0.427509   \n",
       "1          NaN  0.819561 -0.615911  ... -0.113263 -0.457263 -0.427509   \n",
       "2     0.291224 -1.219043  0.109793  ... -0.113263 -0.457263 -0.427509   \n",
       "3     1.092849 -1.219043  0.109793  ... -0.113263 -0.457263 -0.427509   \n",
       "4    -0.466588  0.084134 -1.585803  ... -0.113263 -0.457263 -0.427509   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3418       NaN -1.219043  0.711807  ... -0.113263 -0.457263 -0.427509   \n",
       "3419 -0.292831  0.819561  0.109793  ... -0.113263 -0.457263 -0.427509   \n",
       "3420       NaN  0.084134  0.109793  ... -0.113263 -0.457263 -0.427509   \n",
       "3421  0.813510  1.329679 -1.585803  ... -0.113263 -0.457263 -0.427509   \n",
       "3422  0.414988  0.819561  1.235903  ... -0.113263 -0.457263 -0.427509   \n",
       "\n",
       "            34        35        36        37        38        39        40  \n",
       "0     1.321538 -0.636159  2.246219 -0.468445 -0.949614 -0.222886 -0.233042  \n",
       "1     1.553357 -2.135502  0.987608  2.123623 -2.097699 -0.222886       NaN  \n",
       "2    -0.874182  0.281114  0.540742 -0.468445  0.064084 -0.222886 -0.233042  \n",
       "3    -0.874182  0.456898  0.227531 -0.468445  0.252883 -0.222886 -0.233042  \n",
       "4     0.821645       NaN -1.140070 -0.468445 -1.096429 -0.222886       NaN  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "3418  1.321538  2.082672       NaN -0.468445  1.506523 -0.222886 -0.233042  \n",
       "3419  1.553357 -0.191679 -0.552582 -0.468445  0.648379 -0.222886 -0.233042  \n",
       "3420  1.321538  0.404293  2.169303 -0.468445 -0.276885 -0.222886 -0.233042  \n",
       "3421 -0.874182  0.397339 -1.456878 -0.468445  0.039927 -0.222886 -0.233042  \n",
       "3422 -0.874182       NaN -0.167892 -0.468445  0.764431  4.486606 -0.233042  \n",
       "\n",
       "[3423 rows x 41 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Passemos à normalização dos dados\n",
    "scaler_p = PowerTransformer()\n",
    "scaler_st = StandardScaler()\n",
    "scaler_min= MinMaxScaler()\n",
    "\n",
    "#Transformar dados\n",
    "X_bio_train_p=scaler_p.fit_transform(X_bio_train)\n",
    "X_bio_test_p=scaler_p.fit_transform(X_bio_test)\n",
    "\n",
    "X_bio_train_st=scaler_st.fit_transform(X_bio_train)\n",
    "X_bio_test_st=scaler_st.fit_transform(X_bio_test)\n",
    "\n",
    "X_bio_train_min=scaler_min.fit_transform(X_bio_train)\n",
    "X_bio_test_min=scaler_min.fit_transform(X_bio_test)\n",
    "\n",
    "pd.DataFrame(X_bio_train_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90d5585",
   "metadata": {},
   "source": [
    "Com os dados normalizados, podemos passar à imputação dos valores em falta. Escolheu-se o método de imputação utilizando o K-Nearest Neighbours em todos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23553b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tratamento dos Missing values -> Utilizar Imputação de KNN\n",
    "imputer = KNNImputer(n_neighbors=3, weights=\"uniform\")\n",
    "\n",
    "imputer.fit(X_bio_train_p)\n",
    "X_bio_train_p=imputer.transform(X_bio_train_p)\n",
    "X_bio_test_p=imputer.transform(X_bio_test_p)\n",
    "\n",
    "imputer.fit(X_bio_train_st)\n",
    "X_bio_train_st=imputer.transform(X_bio_train_st)\n",
    "X_bio_test_st=imputer.transform(X_bio_test_st)\n",
    "\n",
    "imputer.fit(X_bio_train_min)\n",
    "X_bio_train_min=imputer.transform(X_bio_train_min)\n",
    "X_bio_test_min=imputer.transform(X_bio_test_min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3de335",
   "metadata": {},
   "source": [
    "Resta apenas ver quais são as variáveis mais relevantes. Para tal, vamos utilizar dois métodos diferentes e posteriormente comparar: Stepwise Feature Selection e Random Forests para a seleção de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "689a3a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepwise\n",
      "The features selected are columns:  [ 0  2  5  6  7 10 15 21 22 33]\n",
      "F1 RFs:  0.9775\n",
      "F1 DTs:  0.9711\n",
      "F1 LRs:  0.9493\n",
      "F1 Avg:   0.9660\n",
      "\n",
      "Random Forests\n",
      "Default threshold:  0.035\n",
      "The features selected are columns:  [ 0  2  4  5  6 10 21 33 35 40]\n",
      "F1 RFs:  0.9769\n",
      "F1 DTs:  0.9712\n",
      "F1 LRs:  0.9651\n",
      "F1 Avg:   0.9711\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "\n",
    "print(\"Stepwise\")\n",
    "datasets.append(Step_for(X_bio_train_st, X_bio_test_st, y_bio_train, y_bio_test))\n",
    "\n",
    "print()\n",
    "print(\"Random Forests\")\n",
    "datasets.append(ML_Sel(X_bio_train_st, X_bio_test_st, y_bio_train, y_bio_test, 0.035))\n",
    "\n",
    "# escolher o conjunto de treino com maior f1_avg\n",
    "_, X_train, X_test = max(datasets, key= lambda x : x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e26f4",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263094c5",
   "metadata": {},
   "source": [
    "Nesta segunda parte iremos criar modelos que consigam prevêr se um químico é ou não biodegradável. Iremos também otimizar estes modelos consoante os seus hiperparâmetros. Os modelos a ser utilizados são: KNN, SVM, Random Forests, AdaBoost e XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee80dc8f",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c19ca46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 10, 'min_samples_split': 20}\n"
     ]
    }
   ],
   "source": [
    "params = [\n",
    "    {\"max_depth\" : [6,8,10,12,14,16,18,20,22,24,26,28,30],\n",
    "    \"min_samples_leaf\" : [1,2,5,10,20],\n",
    "    \"min_samples_split\" : [2,5,10,20],\n",
    "    \"criterion\":['gini','entropy']}]\n",
    "\n",
    "grid_search_treeclass = GridSearchCV(\n",
    "    DecisionTreeClassifier(), params, scoring=\"f1\", cv=kf, n_jobs=-1)\n",
    "\n",
    "grid_search_treeclass.fit(X_train,  y_bio_train)\n",
    "print(grid_search_treeclass.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d558fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is:  0.9489\n",
      "The Precision is:  0.9669\n",
      "The Recall is:  0.9719\n",
      "The F1 score is:  0.9694\n",
      "The Matthews correlation coefficient is:  0.8145\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0     1\n",
      "0  477    95\n",
      "1   80  2771\n"
     ]
    }
   ],
   "source": [
    "printClassResults(*CrossValidation(X_train, y_bio_train, kf, grid_search_treeclass.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708fde32",
   "metadata": {},
   "source": [
    "Regressão Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80b7de8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.7000000000000001, 'max_iter': 999999}\n"
     ]
    }
   ],
   "source": [
    "params = [\n",
    "    {\"C\" : [x*0.1 for x in range(1,11)],\n",
    "    \"max_iter\" : [999999]}]\n",
    "\n",
    "grid_search_log = GridSearchCV(\n",
    "    LogisticRegression(), params, scoring=\"f1\", cv=kf, n_jobs=-1)\n",
    "\n",
    "grid_search_log.fit(X_train, y_bio_train)\n",
    "print(grid_search_log.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1980202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is:  0.9375\n",
      "The Precision is:  0.9426\n",
      "The Recall is:  0.9849\n",
      "The F1 score is:  0.9633\n",
      "The Matthews correlation coefficient is:  0.7617\n",
      "\n",
      "This is the Confusion Matrix\n",
      "     0     1\n",
      "0  401   171\n",
      "1   43  2808\n"
     ]
    }
   ],
   "source": [
    "printClassResults(*CrossValidation(X_train, y_bio_train, kf, grid_search_log.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52e69eb",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973e5504",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4acb4e",
   "metadata": {},
   "source": [
    "XGBOOST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
